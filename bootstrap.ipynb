{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling with vs. without Replacement\n",
    "\n",
    "Many questions of probability and statistics have to do with sampling from a population. Sometimes it is appropriate to imagine that the initial population is reset after each draw, and sometimes it is not.\n",
    "\n",
    "Here's a case of the former: I go around interviewing people and I record their birthdays.\n",
    "\n",
    "Clearly, two people can have the same birthday, and so I need each birthday to be available for every draw (i.e. interview). This is sampling **with replacement**. (One might even imagine that I interview some people more than once (by random chance).) Note in particular that draws in this context are mutually **independent**.\n",
    "\n",
    "Here's a case of the latter: I am dealt thirteen cards to make a bridge hand. I can't have the same card appear twice in a single hand, so if I am thinking about the statistics of bridge hands, then I'm thinking about sampling **without replacement**.\n",
    "\n",
    "Clearly this difference has an effect on correct calculation.\n",
    "\n",
    "Consider these two similar cases:\n",
    "\n",
    "**Case 1**: We're playing war. Each of us has a deck of cards, and we each turn over one card at a time, the player with the higher card collecting both. A tie in rank triggers \"war\", where more cards are laid down and then another contest is initiated on top of the now larger \"pot\" of cards.\n",
    "\n",
    "Question: What are the chances that you and I turn over cards with the same rank on one round of war?\n",
    "\n",
    "Answer: This is effectively a problem of cards drawn *with replacement*: I can just model this with two draws from a single deck. And so I calculate as follows:\n",
    "\n",
    "I can draw any card first, so that's 52/52. The second card must match the first in rank, so that's 4/52. Thus the chances are $\\frac{52}{52}\\times\\frac{4}{52} = \\frac{1}{13}$.\n",
    "\n",
    "**Case 2**: I am dealt a two-card blackjack hand from a single deck. (Good luck finding this game in Las Vegas!)\n",
    "\n",
    "Question: What are the chances that I am dealt a pair?\n",
    "\n",
    "Answer: The two events, one for each card being passed my way, are *not independent*. What the second card is likely to be is affected by what the first card is. For example, if the first card dealt me is the ace of spades, then there is now zero chance that the second card dealt me will be the ace of spades. (Whereas, if the first card is something else, then the chance that the second card be the ace of spades is greater than 0.) And so this is a problem of cards drawn *without replacement*.\n",
    "\n",
    "So I calculate as follows:\n",
    "\n",
    "I can draw any card first, so that's 52/52. The second card must match the first in rank, so that's 3/51. There are three left of whatever rank matches my first card, and 51 total cards left. Thus the chances are $\\frac{52}{52}\\times\\frac{3}{51} = \\frac{1}{17}$.\n",
    "\n",
    "Bootstrapping is a sort of sampling ***with replacement***.\n",
    "\n",
    "I can effect both sorts of sampling with the `choice()` function inside NumPy's `random` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ['red', 'green', 'blue']\n",
    "np.random.choice(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the defaults of this function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling from an Unknown Distribution\n",
    "\n",
    "Bootstrapping is used when the shape of the population's distribution is unknown. To simulate this situation, let's make several distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = stats.norm(loc=10, scale=5)\n",
    "expon = stats.expon(loc=5, scale=5)\n",
    "uni = stats.uniform(loc=5, scale=10)\n",
    "\n",
    "dists = [norm, expon, uni]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these distributions all have the same mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.mean() == expon.mean() == uni.mean() == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dists(dists, n=100):\n",
    "    \"\"\"Plot histograms of the distributions in dists.\"\"\"\n",
    "    fig, axs = plt.subplots(1, len(dists), figsize=(5*len(dists), 5))\n",
    "    for ax, dist in zip(axs, dists):\n",
    "        ax.hist(dist.rvs(10000))\n",
    "        ax.set_xlim(0, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dists(dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a distribution at random:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = np.random.choice(dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a million points from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "pop = dist.rvs(10**6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a sample of 1000 from that million:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.random.choice(pop, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample mean, $\\bar{x}$, is *near* the population mean, $\\mu$, but there's a certain gap between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Algorithm in Words\n",
    "\n",
    "What we want to do now is what we just did, but *many* times. We can record statistics about each sample, and **then** do statistics on those statistics!\n",
    "\n",
    "The idea is that statistics on this collection of samples, each made **with replacement**, will be a good approximation of the population parameters from which our original sample was drawn. And the more samples we take, the better our approximation should be. In this way we are \"pulling ourselves up by our own bootstraps\" to make inferences about the population as a whole.\n",
    "\n",
    "**Note that we are NOT making inferences about the population distribution, but only about some population parameter of interest (like the mean).**\n",
    "\n",
    "Let's see what happens when we record the mean and the 95th percentile of each sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "# Initialize an empty list\n",
    "bootstrap_samples = []\n",
    "\n",
    "# Initialize an array of means\n",
    "bootstrap_sample_means = np.zeros(1000)\n",
    "\n",
    "# And another of 95th percentiles\n",
    "bootstrap_sample_95pcts = np.zeros(1000)\n",
    "for i in range(1000):\n",
    "    \n",
    "    # Take 1000 points from one of the dists\n",
    "    bootstrap_sample = np.random.choice(sample, size=1000)\n",
    "    \n",
    "    # Add that to the list\n",
    "    bootstrap_samples.append(bootstrap_sample)\n",
    "    \n",
    "    # Add the mean to the means' array\n",
    "    bootstrap_sample_means[i] = bootstrap_sample.mean()\n",
    "    \n",
    "    # Add the 95th percentile to the percentiles'array\n",
    "    bootstrap_sample_95pct = np.percentile(a=bootstrap_sample, q=95)\n",
    "    bootstrap_sample_95pcts[i] = bootstrap_sample_95pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_sample_means[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_sample_95pcts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, figsize=(6, 10))\n",
    "ax[0].hist(bootstrap_sample_means)\n",
    "ax[1].hist(bootstrap_sample_95pcts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_sample_means.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(a=sample, q=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_sample_95pcts.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(a=pop, q=95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Bootstrap?\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)) is helpful on this.\n",
    "\n",
    "With a bootstrap we are simulating the relationship between population and sample by treating our sample as the population. In that case we can actually measure the error between our estimates (made through resampling) and the true sample statistics.\n",
    "\n",
    "\"Adèr et al. recommend the bootstrap procedure for the following situations (Adèr, H. J., Mellenbergh G. J., & Hand, D. J. (2008). *Advising on research methods: A consultant's companion*. Huizen, The Netherlands: Johannes van Kessel Publishing. ISBN 978-90-79418-01-5.):\n",
    "\n",
    "- When the theoretical distribution of a statistic of interest is complicated or unknown. Since the bootstrapping procedure is distribution-independent it provides an indirect method to assess the properties of the distribution underlying the sample and the parameters of interest that are derived from this distribution.\n",
    "- When the sample size is insufficient for straightforward statistical inference. If the underlying distribution is well-known, bootstrapping provides a way to account for the distortions caused by the specific sample that may not be fully representative of the population.\n",
    "- When power calculations have to be performed, and a small pilot sample is available. Most power and sample size calculations are heavily dependent on the standard deviation of the statistic of interest. If the estimate used is incorrect, the required sample size will also be wrong. One method to get an impression of the variation of the statistic is to use a small pilot sample and perform bootstrapping on it to get impression of the variance.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping as Comparison Tool\n",
    "\n",
    "In the context of hypothesis testing, we can use bootstrapping to test whether there is a significant difference between two samples. The idea is this:\n",
    "\n",
    "Suppose that Sample A and Sample B seem to be significantly different in some feature. Now, if we were (i) to throw A and B together into one big pool, and then (ii) to construct new samples (with replacement) from this pool, any similar difference we see between the samples we make would be evidence that the original difference between A and B was not significant after all. So if we do this sampling experiment lots of times, and we *rarely* see a difference between our two samples like we saw between A and B, then we can be confident that there is some significant difference between A and B.\n",
    "\n",
    "Let's try this with the Instagram control and experimental groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control = pd.read_csv('data/control.csv', index_col=0)\n",
    "experiment = pd.read_csv('data/experiment.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(a, b):\n",
    "    universe = np.append(a, b)\n",
    "    universe_shuffled = np.random.choice(universe, size=len(universe), replace=True)\n",
    "    new_a = universe_shuffled[:len(a)]\n",
    "    new_b = universe_shuffled[len(a):]\n",
    "    return new_a, new_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_1 = control['Likes_Given_Con']\n",
    "grp_2 = experiment['Likes_Given_Exp']\n",
    "orig_mean = grp_2.mean() - grp_1.mean()\n",
    "orig_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr = 0\n",
    "samples = 10000\n",
    "for _ in range(samples):\n",
    "    a, b = bootstrap(grp_1, grp_2)\n",
    "    if abs(a.mean() - b.mean()) > orig_mean:\n",
    "        ctr += 1\n",
    "print('p-value:' + str(ctr / samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation to Permutation Tests\n",
    "\n",
    "This use of bootstrapping as a comparision tool is similar in concept to the idea of a **permutation test**. The idea here is that, if some statistical test yields a high significance result (low p-value), then we should *not* see the same significance if we were to permute the labels of our data points, sampling randomly and indiscriminately from the control and the experimental groups.\n",
    "\n",
    "The main difference is that bootstrapping always samples **with replacement** while permutation tests operate **without replacement** (as per the nature of permutations!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Permutation Test Example\n",
    "\n",
    "Let's check out the diamonds datset in `seaborn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds = sns.load_dataset('diamonds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=diamonds, x='clarity', y='price');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least as far as this dataset is concerned, diamonds with a clarity rating of \"SI2\" seem to demand a significantly higher price than diamonds with a clarity rating of \"VVS1\". Let's conduct a permutation test to make sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we'll calculate the mean price of each group\n",
    "\n",
    "vvs1_mean = diamonds[diamonds['clarity'] == 'VVS1']['price'].mean()\n",
    "si2_mean = diamonds[diamonds['clarity'] == 'SI2']['price'].mean()\n",
    "\n",
    "print(vvs1_mean)\n",
    "print(si2_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is borrowed from the [*Principles and Techniques of Data Science*, Sect. 18.1](https://www.textbook.ds100.org/ch/18/hyp_introduction.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(series):\n",
    "    '''\n",
    "    Shuffles a series and resets index to preserve shuffle when adding series\n",
    "    back to DataFrame.\n",
    "    '''\n",
    "    \n",
    "    return series.sample(frac=1, replace=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty array of mean differences\n",
    "diffs = np.array([])\n",
    "\n",
    "iterations = 1000\n",
    "for _ in range(iterations):\n",
    "    \n",
    "    # Add a \"shuffled\" column that will contain a shuffle of diamond prices\n",
    "    diamonds['Shuffled'] = shuffle(diamonds['price'])\n",
    "    \n",
    "    # Construct the difference in means between the two arbitrarily labeled\n",
    "    # groups\n",
    "    diff = diamonds[diamonds['clarity'] == 'SI2']['Shuffled'].mean() -\\\n",
    "    diamonds[diamonds['clarity'] == 'VVS1']['Shuffled'].mean()\n",
    "    \n",
    "    # Add the difference to our array of mean differences\n",
    "    diffs = np.append(diffs, diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a measure of p-value by counting the number of differences that are\n",
    "# greater than the difference between the real means of the two groups\n",
    "p = np.count_nonzero(diffs >= si2_mean - vvs1_mean) / iterations\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping Real Data\n",
    "\n",
    "Below we read in a dataset containing information about public toilets in Berlin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "berlin = pd.read_excel('data/20191101_berlinertoiletten-2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "berlin.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "berlin['Price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "\n",
    "for _ in range(10000):\n",
    "    sample = np.random.choice(berlin['Price'].values, size=len(berlin['Price']))\n",
    "    means.append(np.mean(sample))\n",
    "\n",
    "plt.hist(means);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: To what extent could we use these results to draw inferences about public toilet prices in all of Germany? Or all of Europe? Or about past or future toilet prices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping in Linear Regression\n",
    "\n",
    "[Here](https://www.textbook.ds100.org/ch/18/hyp_regression.html) is a great example of how we could use bootstrapping in the context of linear regression.\n",
    "\n",
    "The basic idea is that we want some measure of the error of our coefficients. Bootstrapping to the rescue! If we fit *many* linear regressions to different bootstrapped samples of our data and calculate the coefficients each time, we can then have a distribution of coefficients that we can use as a confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X, Y = make_regression(n_features=2, noise=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, figsize=(6, 10))\n",
    "ax[0].scatter(X[:, 0], Y)\n",
    "ax[1].scatter(X[:, 1], Y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X, columns=('X1', 'X2'))\n",
    "df_plus_y = pd.concat([df, pd.Series(Y, name='Y')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now with bootstrapping\n",
    "\n",
    "X1_coefs = []\n",
    "for _ in range(1000):\n",
    "    inds = np.random.choice(range(100), size=10)\n",
    "    rows = df_plus_y.iloc[inds, :]\n",
    "    lr = LinearRegression().fit(rows[['X1', 'X2']], rows['Y'])\n",
    "    X1_coefs.append(lr.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_sorted = sorted(X1_coefs)\n",
    "print(coefs_sorted[24])\n",
    "print(coefs_sorted[974])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_coefs = []\n",
    "for _ in range(1000):\n",
    "    inds = np.random.choice(range(100), size=10)\n",
    "    rows = df_plus_y.iloc[inds, :]\n",
    "    lr = LinearRegression().fit(rows[['X1', 'X2']], rows['Y'])\n",
    "    X2_coefs.append(lr.coef_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_sorted = sorted(X2_coefs)\n",
    "print(coefs_sorted[24])\n",
    "print(coefs_sorted[974])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of these Results to `statsmodels`'s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.OLS(endog=Y, exog=X).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of these Results to `seaborn`'s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm1 = sns.lmplot(data=df_plus_y, x='X1', y='Y');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm2 = sns.lmplot(data=df_plus_y, x='X2', y='Y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping Challenge\n",
    "\n",
    "\n",
    "Suppose we had the following two samples of automobile MPG ratings. The question is whether Group 2 (the experimental group) has a significantly higher MPG rating than Group 1 (the control group).\n",
    "\n",
    "First, we'll make some preliminary calculations and run a hypothesis test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the files:\n",
    "\n",
    "grp_1 = pd.read_csv('data/group1.csv', index_col=0, squeeze=True)\n",
    "grp_2 = pd.read_csv('data/group2.csv', index_col=0, squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_2.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_1.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grp_2.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(grp_1, grp_2, equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cohen_d(group1, group2):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes Cohen's d.\n",
    "    \"\"\"\n",
    "    \n",
    "    # group1: Series or NumPy array\n",
    "    # group2: Series or NumPy array\n",
    "\n",
    "    # returns a floating point number \n",
    "\n",
    "    diff = group1.mean() - group2.mean()\n",
    "\n",
    "    n1 = len(group1)\n",
    "    n2 = len(group2)\n",
    "    var1 = group1.var(ddof=1)\n",
    "    var2 = group2.var(ddof=1)\n",
    "\n",
    "    # Calculate the pooled threshold\n",
    "    pooled_var = ((n1-1) * var1 + (n2-1) * var2) / (n1 + n2 - 2)\n",
    "    \n",
    "    # Calculate Cohen's d statistic\n",
    "    d = diff / np.sqrt(pooled_var)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cohen_d(grp_1, grp_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Construct 10000 bootstrap samples of the *difference in means* between the two groups. Then order the differences and take the 250th and 9750th values to construct a 95%-confidence interval around our estimate of the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now bootstrap!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
